{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence to Sequence Models\n",
    "\n",
    "We will now look at another major architecture called Seq2Seq which basically takes sequences as input and outputs another sequence. Where can we use this?\n",
    "\n",
    "We generally use this for machine translation. Given a set of words in a language, we find what will be the its translation in another language. We will be attempting to do this for translating English to Hindi. We will also look at some new metrics to gauge the \"correctness\" of our model.\n",
    "\n",
    "To read more about Seq2Seq : https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/\n",
    "\n",
    "\n",
    "We will start by importing all necessary libraries and defining directory paths..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For file handling...\n",
    "import pandas as pd\n",
    "import os,string\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "from nltk import wordpunct_tokenize\n",
    "\n",
    "\n",
    "#For dataset creation...\n",
    "from torch.utils.data import Dataset,DataLoader,random_split\n",
    "\n",
    "\n",
    "#For model building...\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# For model training...\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm,tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join(os.getcwd(),\"data\",\"english_to_hindi.txt\")\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data reading\n",
    "\n",
    "This section will be geared towards building functions for:\n",
    "1. Reading the text file\n",
    "2. Dealing with missing values if any\n",
    "3. Tokenizing the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN    0\n",
      "HI    0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EN</th>\n",
       "      <th>HI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Help!</td>\n",
       "      <td>बचाओ!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jump.</td>\n",
       "      <td>उछलो.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jump.</td>\n",
       "      <td>कूदो.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jump.</td>\n",
       "      <td>छलांग.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hello!</td>\n",
       "      <td>नमस्ते।</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       EN       HI\n",
       "0   Help!    बचाओ!\n",
       "1   Jump.    उछलो.\n",
       "2   Jump.    कूदो.\n",
       "3   Jump.   छलांग.\n",
       "4  Hello!  नमस्ते।"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def readFile(path,chkNa=True):\n",
    "    \"\"\"\n",
    "        Load data from a text file. The file must have Lang1(delimiter)Lang2 in each row.\n",
    "        Eg : \"Hello Hallo\" or \"Hello Ola\" {here, delimiter was space} \n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(path,header=None,sep=\"\\t\",names=[\"EN\",\"HI\"])\n",
    "        if chkNa:\n",
    "            print(df.isna().sum())\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"{path} does not specify a text file.\")    \n",
    "    except OSError:\n",
    "        print(f\"{path} does not exist\")\n",
    "\n",
    "#checking to make sure...\n",
    "df = readFile(DATA_PATH)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background on the \"HI\" part seen above\n",
    "\n",
    "The above dataframe holds strings from UTF-8 character encoding. The strings in the \"HI\" column are all formed from the devnagiri script. Unicode is a larger character map which encompasses(or \"supports\", for the layman :) ) many scripts like Cyrillic ( Russian, Ukranian, etc.) and those accents in french as well as the Umlauts in German(the a,e,i,o,u with a \"snakebite\" on top). Dealing with these strings is fairly easy if you know how they are formed. A good place to understand this is:\n",
    "\n",
    "https://www.joelonsoftware.com/2003/10/08/the-absolute-minimum-every-software-developer-absolutely-positively-must-know-about-unicode-and-character-sets-no-excuses/\n",
    "\n",
    "http://www.utf-8.com/\n",
    "\n",
    "To help you wrap our heads around, all the strings are made of characters. However, All the characters are represented in memory as streams of bits. As we wanted to incorporate more languages, we increased the number of bits. To look at what is the integer representation of a character or vice-versa, we use following functions:\n",
    "\n",
    "ord(char) -> int\n",
    "\n",
    "chr(int) -> char\n",
    "\n",
    "Note that the two functions are inverses of each other i.e, ord(chr(someInt) = someInt\n",
    "\n",
    "https://stackoverflow.com/questions/38454521/how-to-print-character-using-its-unicode-value-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2304\n",
      "2431\n"
     ]
    }
   ],
   "source": [
    "strin = df[\"HI\"][0]\n",
    "\n",
    "# The first letter in Devnagiri script...\n",
    "print(ord(\"ऀ\"))\n",
    "\n",
    "# The last letter in Devnagiri script...\n",
    "print(ord(\"ॿ\"))\n",
    "\n",
    "#The difference between these two should cover all the letters...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['मुझे', 'टिकटें', 'कहाँ', 'से', 'लेनीं', 'होंगीं']\n",
      "['Where', 'should', 'I', 'pick', 'the', 'tickets', 'up']\n",
      "['तुम', 'आज', 'सुबह', 'यहाँ', 'क्यों', 'आए']\n",
      "['Why', 'did', 'you', 'come', 'here', 'this', 'morning']\n"
     ]
    }
   ],
   "source": [
    "def clean(txt):\n",
    "    unwanted = \"~|\\\\/_।.?,*@#$%^&(){}[]=+\\\"-'\"\n",
    "    for char in unwanted:\n",
    "        txt = txt.replace(char,' ')\n",
    "    return txt\n",
    "\n",
    "def tokenize(txt):\n",
    "    txt = clean(txt) \n",
    "    tokens = txt.split()\n",
    "    return tokens\n",
    "\n",
    "for i in range(2008,2010):\n",
    "    #print(df[\"HI\"][i])\n",
    "    print(tokenize(df[\"HI\"][i]))\n",
    "    print(tokenize(df[\"EN\"][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN\n",
      "HI\n"
     ]
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Dataset and Dataloaders\n",
    "\n",
    "This section will deal with generating our torch dataset and datloaders. Our dataset class will be:\n",
    "1. Taking a txt file path as input\n",
    "2. Reading the txt file\n",
    "3. Tokenizing the text data\n",
    "4. Creating vocabulary\n",
    "5. Creating charMaps and reverse charMaps\n",
    "6. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EngHinData(Dataset):    \n",
    "    def __init__(self,path,maxVocabSize=500):\n",
    "        \"\"\"\n",
    "            Read a text file from path and generate the input and target sequences\n",
    "            Also generate english and hindi vocabulary with a max size.\n",
    "            The most commonly occuring words are chosen.\n",
    "        \"\"\"\n",
    "        self.maxVocabSize = maxVocabSize\n",
    "        \n",
    "        df = readFile(path,chkNa=False)\n",
    "        self.df = self.tokenizeDf(df)\n",
    "        \n",
    "        #Generate a vocabulary for both languages...\n",
    "        enVocab = self.mostFreqTokens(self.df.ENTokenized.tolist())\n",
    "        hiVocab = self.mostFreqTokens(self.df.HITokenized.tolist())\n",
    "        \n",
    "        #Replace rare tokens with \"<UNK>\"\n",
    "        self.replaceRareTokens(self.df)\n",
    "        #Impute zero length targets...\n",
    "        self.findZeroTargets()\n",
    "        #Remove all datarows with >20% unknowns...\n",
    "        self.df = self.removeHighUnk(self.df)\n",
    "        \n",
    "        # Create char maps and reverse char maps\n",
    "        self.enEncoder,self.enDecoder = self.generateMaps(enVocab,rev=True)\n",
    "        self.hiEncoder,self.hiDecoder = self.generateMaps(hiVocab,rev=True)\n",
    "        \n",
    "        # Add <BEG> and <END> to all tokens...\n",
    "        self.appendExtras(self.df)\n",
    "        \n",
    "        # change tokens to indices...\n",
    "        self.token2idx(self.df)\n",
    "        \n",
    "        # Drop all columns except num...\n",
    "        self.df.drop([\"level_0\",\"index\",\"EN\",\"HI\",\"ENTokenized\",\"HITokenized\"],axis=1,inplace=True)\n",
    "        self.df.reset_index(inplace=True)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def __getitem__(self,i):\n",
    "        return self.df.ENNum[i],self.df.HINum[i]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    \n",
    "    def token2idx(self,df):\n",
    "        df[\"ENNum\"] = df.ENTokenized.apply(lambda tokenList: [self.enEncoder[token] for token in tokenList])\n",
    "        df[\"HINum\"] = df.HITokenized.apply(lambda tokenList: [self.hiEncoder[token] for token in tokenList])\n",
    "    \n",
    "    \n",
    "    def appender(self,tokenList):\n",
    "        tokenList.insert(0,\"<BEG>\")\n",
    "        tokenList.append(\"<END>\")\n",
    "        return tokenList\n",
    "    \n",
    "        \n",
    "    def appendExtras(self,df):\n",
    "        \"\"\"\n",
    "            Adds <BEG> and <END> at the start and end of each tokenList\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        df.ENTokenized.apply(self.appender)\n",
    "        df.HITokenized.apply(self.appender)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def generateMaps(self,vocab,rev=False):\n",
    "        \"\"\"\n",
    "            Generates a dictionary {char : idx}\n",
    "            If rev is set to True, a reverse map will also be generated {idx : char}\n",
    "        \"\"\"\n",
    "        extras = [\"<PAD>\",\"<BEG>\",\"<END>\",\"<UNK>\"]    \n",
    "        charMap = {char : idx for idx,char in enumerate(vocab)}\n",
    "        for extra in extras:\n",
    "            charMap[extra] = len(charMap)\n",
    "        \n",
    "        if not rev:\n",
    "            return charMap\n",
    "        else:\n",
    "            revCharMap = {idx : char for char,idx in charMap.items()}\n",
    "            return charMap,revCharMap \n",
    "        \n",
    "    \n",
    "    def tokenizeDf(self,df):\n",
    "        df[\"ENTokenized\"] = df.EN.apply(tokenize)\n",
    "        df[\"HITokenized\"] = df.HI.apply(tokenize)\n",
    "        return df\n",
    "    \n",
    "    def replaceRareTokens(self,df):\n",
    "        commonInputs = self.mostFreqTokens(df.ENTokenized.tolist())\n",
    "        commonTargets = self.mostFreqTokens(df.HITokenized.tolist())\n",
    "        \n",
    "        df.loc[:, 'ENTokenized'] = df.ENTokenized.apply(\n",
    "            lambda tokens: [token if token in commonInputs \n",
    "                            else \"<UNK>\" for token in tokens]\n",
    "        )\n",
    "        df.loc[:, 'HITokenized'] = df.HITokenized.apply(\n",
    "            lambda tokens: [token if token in commonTargets\n",
    "                            else \"<UNK>\" for token in tokens]\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def mostFreqTokens(self,sequence):\n",
    "        allTokens = [word for sent in sequence for word in sent]\n",
    "        common_tokens = set(list(zip(*Counter(allTokens).most_common(self.maxVocabSize - 4)))[0])\n",
    "        return common_tokens\n",
    "    \n",
    "    def removeHighUnk(self, df, threshold=0.8):\n",
    "        \"\"\"Remove sequences with mostly <UNK>.\"\"\"\n",
    "        calculate_ratio = (\n",
    "            lambda tokens: sum(1 for token in tokens if token != '<UNK>')/ len(tokens) > threshold\n",
    "        )\n",
    "        \n",
    "        df = df[df.ENTokenized.apply(calculate_ratio)]\n",
    "        df = df[df.HITokenized.apply(calculate_ratio)]\n",
    "        df.reset_index(inplace=True)\n",
    "        return df\n",
    "    \n",
    "        \n",
    "    def findZeroTargets(self):\n",
    "        badVals = []\n",
    "        for i,val in enumerate(self.df.HITokenized.values):\n",
    "            if len(val)==0:\n",
    "                badVals.append(i)\n",
    "        \n",
    "        print(f\"Found {len(badVals)} bad values...Imputing them...\")\n",
    "        self.df.drop(badVals,axis=0,inplace=True)\n",
    "        self.df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 bad values...Imputing them...\n"
     ]
    }
   ],
   "source": [
    "ds = EngHinData(DATA_PATH,5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What happened?\n",
    "\n",
    "The class defined above does the following:\n",
    "1. It reads from the path specified text file\n",
    "2. It creates a pandas dataframe from it\n",
    "3. It tokenizes both the english and the hindi sentences.\n",
    "4. It found the most frequently occuring tokens.\n",
    "5. Using the most frequent tokens, it replaced other tokens as UNK since they wont be in our charMap.\n",
    "6. It removed the datarows which have more than 20% UNKnowns (by default, can be changed).\n",
    "7. It creates a charMap (or vocabulary) for both hindi and english languages\n",
    "8. And a reverse charMap which helps to decode back(for testing purposes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>ENNum</th>\n",
       "      <th>HINum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[4997, 1579, 4998]</td>\n",
       "      <td>[4997, 3017, 4998]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[4997, 1579, 4998]</td>\n",
       "      <td>[4997, 1795, 4998]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[4997, 750, 4998]</td>\n",
       "      <td>[4997, 371, 4998]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[4997, 4673, 3460, 4816, 4998]</td>\n",
       "      <td>[4997, 1341, 4397, 2884, 4998]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[4997, 443, 2992, 4998]</td>\n",
       "      <td>[4997, 3894, 108, 2535, 4998]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>[4997, 4128, 2409, 4998]</td>\n",
       "      <td>[4997, 4590, 3594, 1697, 4998]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>[4997, 3134, 4998]</td>\n",
       "      <td>[4997, 427, 4633, 4035, 4998]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>[4997, 4240, 4423, 4998]</td>\n",
       "      <td>[4997, 4926, 3606, 4998]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>[4997, 4240, 4423, 4998]</td>\n",
       "      <td>[4997, 556, 3606, 4998]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>[4997, 4240, 4423, 4998]</td>\n",
       "      <td>[4997, 4926, 708, 4998]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                           ENNum                           HINum\n",
       "0      0              [4997, 1579, 4998]              [4997, 3017, 4998]\n",
       "1      1              [4997, 1579, 4998]              [4997, 1795, 4998]\n",
       "2      2               [4997, 750, 4998]               [4997, 371, 4998]\n",
       "3      3  [4997, 4673, 3460, 4816, 4998]  [4997, 1341, 4397, 2884, 4998]\n",
       "4      4         [4997, 443, 2992, 4998]   [4997, 3894, 108, 2535, 4998]\n",
       "5      5        [4997, 4128, 2409, 4998]  [4997, 4590, 3594, 1697, 4998]\n",
       "6      6              [4997, 3134, 4998]   [4997, 427, 4633, 4035, 4998]\n",
       "7      7        [4997, 4240, 4423, 4998]        [4997, 4926, 3606, 4998]\n",
       "8      8        [4997, 4240, 4423, 4998]         [4997, 556, 3606, 4998]\n",
       "9      9        [4997, 4240, 4423, 4998]         [4997, 4926, 708, 4998]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19736, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.99 * len(ds))\n",
    "test_size = len(ds) - train_size\n",
    "train_ds, test_ds = torch.utils.data.random_split(ds, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collation function and dataloaders\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def collate(batch):\n",
    "    \n",
    "    inputs = [torch.LongTensor(item[0]) for item in batch]\n",
    "    targets = [torch.LongTensor(item[1]) for item in batch]\n",
    "    \n",
    "    \n",
    "    # Pad sequencse so that they are all the same length (within one minibatch)\n",
    "    padded_inputs = pad_sequence(inputs, padding_value=ds.enEncoder[\"<PAD>\"], batch_first=True)\n",
    "    padded_targets = pad_sequence(targets, padding_value=ds.hiEncoder[\"<PAD>\"], batch_first=True)\n",
    "    \n",
    "    \n",
    "    # Sort by length for CUDA optimizations\n",
    "    lengths = torch.LongTensor([len(x) for x in inputs])\n",
    "    lengths, permutation = lengths.sort(dim=0, descending=True)\n",
    "\n",
    "    return padded_inputs[permutation].to(device), padded_targets[permutation].to(device), lengths.to(device)\n",
    "\n",
    "\n",
    "batchSize = 512\n",
    "train_loader = DataLoader(train_ds, batch_size=batchSize, collate_fn=collate)\n",
    "test_loader = DataLoader(test_ds, batch_size=1, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model\n",
    "\n",
    "The model will have 2 major parts namely the encoder and the decoder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self,vocabSize,embDims,hiddenSize,batchSize):\n",
    "        \n",
    "        super(Encoder,self).__init__()\n",
    "        \n",
    "        # Copy in all the required sizes...\n",
    "        self.batchSize = batchSize\n",
    "        self.hiddenSize= hiddenSize\n",
    "        self.vocabSize = vocabSize\n",
    "        self.embDims = embDims\n",
    "        \n",
    "        \n",
    "        # Encoder architecture...\n",
    "        self.embedding = nn.Embedding(vocabSize,embDims)\n",
    "        self.gru = nn.GRU(self.embDims,self.hiddenSize,batch_first=True)\n",
    "    \n",
    "    \n",
    "    def forward(self,inputs,lengths):\n",
    "        self.batchSize = inputs.size(0)\n",
    "        \n",
    "        \n",
    "        \n",
    "        x = self.embedding(inputs)\n",
    "        \n",
    "        x = pack_padded_sequence(x, lengths, batch_first=True)\n",
    "        output,self.hidden = self.gru(x,self.initWghts())\n",
    "        \n",
    "        output, _ = pad_packed_sequence(output)\n",
    "        \n",
    "        return output,self.hidden\n",
    "    \n",
    "    \n",
    "    def initWghts(self):\n",
    "        wghts = torch.empty(1,self.batchSize,self.hiddenSize)\n",
    "        return nn.init.kaiming_normal_(wghts).to('cuda')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,vocabSize,embDims,encoderSize,decoderSize,batchSize):\n",
    "        \n",
    "        super(Decoder,self).__init__()\n",
    "        \n",
    "        self.batchSize = batchSize\n",
    "        self.vocabSize = vocabSize\n",
    "        self.encoderSize = encoderSize\n",
    "        self.decoderSize = decoderSize\n",
    "        self.embDims = embDims\n",
    "        \n",
    "        self.embedding = nn.Embedding(self.vocabSize,self.embDims)\n",
    "        self.gru = nn.GRU(self.embDims+self.encoderSize,\n",
    "                          self.decoderSize,\n",
    "                         batch_first=True)\n",
    "        \n",
    "        self.fc = nn.Linear(self.encoderSize,self.vocabSize)\n",
    "        \n",
    "        self.W1 = nn.Linear(self.encoderSize,self.decoderSize)\n",
    "        self.W2 = nn.Linear(self.encoderSize,self.decoderSize)\n",
    "        self.V = nn.Linear(self.encoderSize,1)\n",
    "        \n",
    "    def forward(self,targets,hidden,encoderOutput):\n",
    "        self.batchSize = inputs.size(0)\n",
    "        \n",
    "        encoderOutput = encoderOutput.permute(1,0,2)\n",
    "        hiddenTimeAxis = hidden.permute(1,0,2)\n",
    "        \n",
    "        score = torch.tanh(self.W1(encoderOutput)+self.W2(hiddenTimeAxis))\n",
    "        \n",
    "        attention = torch.softmax(self.V(score),dim=1)\n",
    "        \n",
    "        context = attention * encoderOutput\n",
    "        context = torch.sum(context,dim=1)\n",
    "        \n",
    "        x = self.embedding(targets)\n",
    "        x = torch.cat((context.unsqueeze(1),x),-1)\n",
    "        \n",
    "        output,state = self.gru(x,self.initWghts())\n",
    "        output = output.view(-1, output.size(2))\n",
    "        \n",
    "        x = self.fc(output)\n",
    "        \n",
    "        return x,state,attention\n",
    "    \n",
    "    def initWghts(self):\n",
    "        wghts = torch.empty(1,self.batchSize,self.decoderSize)\n",
    "        return nn.init.kaiming_normal_(wghts).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def loss_func(actual,predicted):\n",
    "    \n",
    "    mask = actual.ge(1).float().to('cuda')\n",
    "    #print(predicted.size(),actual.size())\n",
    "    loss = criterion(predicted.squeeze(1),actual) * mask\n",
    "    \n",
    "    return torch.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EngToHinModel(nn.Module):\n",
    "    def __init__(self,inputVocabSize,targetVocabSize,\n",
    "                 hiddenSize,embDims,batchSize,\n",
    "                 targetsStart,targetsEnd):\n",
    "        \n",
    "        super(EngToHinModel,self).__init__()\n",
    "        \n",
    "        self.batchSize = batchSize\n",
    "        self.targetsStart = targetsStart\n",
    "        self.targetsEnd = targetsEnd\n",
    "        \n",
    "        \n",
    "        self.encoder = Encoder(inputVocabSize,embDims,\n",
    "                               hiddenSize,batchSize).to('cuda')\n",
    "        \n",
    "        self.decoder = Decoder(targetVocabSize,embDims,\n",
    "                               hiddenSize,hiddenSize,batchSize).to('cuda')\n",
    "    \n",
    "    def predict(self,inputs,lengths):\n",
    "        self.batchSize= inputs.size(0)\n",
    "        \n",
    "        encoderOutput,encoderHidden = self.encoder(inputs.to('cuda'),lengths)\n",
    "        decoderHidden = encoderHidden\n",
    "        \n",
    "        decoderInput = torch.LongTensor([[self.targetsStart]] * self.batchSize)\n",
    "        \n",
    "        output = []\n",
    "        for _ in range(20):\n",
    "            preds,decoderHidden,_ = self.decoder(decoderInput.to('cuda'),\n",
    "                                             decoderHidden.to('cuda'),\n",
    "                                             encoderOutput.to('cuda'))\n",
    "            \n",
    "            #print(preds.size())\n",
    "            prediction = torch.multinomial(F.softmax(preds,dim=1),1)\n",
    "            decoderInput = prediction\n",
    "            \n",
    "            prediction = prediction.item()\n",
    "            output.append(prediction)\n",
    "            \n",
    "            if prediction == self.targetsEnd:\n",
    "                #print(output)\n",
    "                return output\n",
    "        \n",
    "        return output\n",
    "        \n",
    "    def forward(self,inputs,targets,lengths):\n",
    "        self.batchSize = inputs.size(0)\n",
    "\n",
    "        encOut, encHidden = self.encoder(inputs.to('cuda'),lengths)\n",
    "\n",
    "        decHidden = encHidden\n",
    "\n",
    "        decIn = torch.LongTensor([[self.targetsStart]] * self.batchSize)\n",
    "\n",
    "\n",
    "        #teacher forcing...\n",
    "        loss=0\n",
    "        for ts in range(1,targets.size(1)):\n",
    "            preds,decHidden,_ = self.decoder(decIn.to('cuda'),\n",
    "                                           decHidden.to('cuda'),\n",
    "                                           encOut.to('cuda'))\n",
    "            decIn = targets[:,ts].unsqueeze(1)\n",
    "\n",
    "            loss += loss_func(targets[:,ts],preds)\n",
    "\n",
    "        return loss/targets.size(1)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "myModel = EngToHinModel(inputVocabSize=len(ds.enEncoder),\n",
    "                        targetVocabSize=len(ds.hiEncoder),\n",
    "                        hiddenSize=128,\n",
    "                        embDims=300,\n",
    "                        batchSize=batchSize,\n",
    "                        targetsStart=ds.hiEncoder[\"<BEG>\"],\n",
    "                        targetsEnd=ds.hiEncoder[\"<END>\"] \n",
    "                        ).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02e636db66484a869095a2289513c25e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=39, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch #  1\ttrain_loss: 3.66e-02\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14f1cb887b5d4808adb055fa08306b74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=39, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch #  2\ttrain_loss: 3.48e-02\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b90b979926e48b393eadad34cb0a569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=39, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch #  3\ttrain_loss: 3.33e-02\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "135bc8d0228044529e689d2fd6c06790",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=39, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch #  4\ttrain_loss: 3.17e-02\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f0e05c6126d4c17a92c79f39e688827",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=39, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch #  5\ttrain_loss: 3.02e-02\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd116d5882964b82ad2b8f8e7664a8d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=39, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch #  6\ttrain_loss: 2.89e-02\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7bbd9c40cda44aba46f3d45932a36f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=39, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch #  7\ttrain_loss: 2.79e-02\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61bf26eb5b9745239e251aab508ee445",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=39, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch #  8\ttrain_loss: 2.68e-02\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45e7000310cd4e07a9fe7a93c8313ebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=39, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch #  9\ttrain_loss: 2.52e-02\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7aaa7fefa0647b9b3a2669a9e5dde51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=39, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch # 10\ttrain_loss: 2.36e-02\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22b5002cd4da4d89b90595e09d93be0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=39, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch # 11\ttrain_loss: 2.24e-02\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0b4d652edaa423499b200167d807e13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=39, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch # 12\ttrain_loss: 2.13e-02\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e8156b294de4b55ae4511988a6a0bf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=39, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch # 13\ttrain_loss: 2.02e-02\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25be7758c0594b47966fb50d0649e051",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=39, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch # 14\ttrain_loss: 1.94e-02\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "654ec2dd0bf84197868755fd404f7846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=39, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch # 15\ttrain_loss: 1.89e-02\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "093434484eea4f09ac3c1e2fb2278b8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=39, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch # 16\ttrain_loss: 1.85e-02\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2957dc34017b467cad12acb2ce491c83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=39, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch # 17\ttrain_loss: 1.76e-02\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ae5feca657947dc8db134e6fb980a67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=39, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch # 18\ttrain_loss: 1.63e-02\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deb143a24fc140beb8581a4051de6161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=39, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch # 19\ttrain_loss: 1.54e-02\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41d1176bcd9e4b8aafa9f79f862c85d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Training', max=39, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch # 20\ttrain_loss: 1.48e-02\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam([p for p in myModel.parameters() if p.requires_grad], lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "myModel.train()\n",
    "for epoch in range(20):\n",
    "    total_loss = total = 0\n",
    "    progress_bar = tqdm_notebook(train_loader, desc='Training')\n",
    "    \n",
    "    for inputs, targets, lengths in progress_bar:\n",
    "        # Clean old gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forwards pass\n",
    "        loss = myModel(inputs, targets, lengths)\n",
    "\n",
    "        # Perform gradient descent, backwards pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Take a step in the right direction\n",
    "        optimizer.step()\n",
    "\n",
    "        # Record metrics\n",
    "        total_loss += loss.item()\n",
    "        total += targets.size(1)\n",
    "\n",
    "    train_loss = total_loss / total\n",
    "    \n",
    "    tqdm.write(f'epoch #{epoch + 1:3d}\\ttrain_loss: {train_loss:.2e}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014819368952594595\n"
     ]
    }
   ],
   "source": [
    "print(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(myModel.state_dict(), os.path.join(os.getcwd(),\"models\",\"Seq2SeqForEngHin-attempt3.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EngToHinModel(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(5000, 300)\n",
       "    (gru): GRU(300, 128, batch_first=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(5000, 300)\n",
       "    (gru): GRU(428, 128, batch_first=True)\n",
       "    (fc): Linear(in_features=128, out_features=5000, bias=True)\n",
       "    (W1): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (W2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (V): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myModel = EngToHinModel(inputVocabSize=len(ds.enEncoder),\n",
    "                        targetVocabSize=len(ds.hiEncoder),\n",
    "                        hiddenSize=128,\n",
    "                        embDims=300,\n",
    "                        batchSize=batchSize,\n",
    "                        targetsStart=ds.hiEncoder[\"<BEG>\"],\n",
    "                        targetsEnd=ds.hiEncoder[\"<END>\"] \n",
    "                        ).to('cuda')\n",
    "\n",
    "myModel.load_state_dict(torch.load(os.path.join(os.getcwd(),\"models\",\"Seq2SeqForEngHin-attempt3.pt\")))\n",
    "myModel.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EN :  Super Video CD\n",
      "HI :  नन्हा तथा वाई सीडी\n",
      "\n",
      "EN :  Mouse Navigation\n",
      "HI :  माउस मुक्त\n",
      "\n",
      "EN :  Even Pages Footer\n",
      "HI :  मई के लिए शीर्षक\n",
      "\n",
      "EN :  Path not found\n",
      "HI :  पथ नहीं मिला\n",
      "\n",
      "EN :  Always keep your office tidy\n",
      "HI :  तुम्हारी घड़ी नहीं कर रहे\n",
      "\n",
      "EN :  Hard\n",
      "HI :  पतला\n",
      "\n",
      "EN :  Decrease Font Sizes\n",
      "HI :  फ़ॉन्ट आकार परियोजनाएँ\n",
      "\n",
      "EN :  Browsing\n",
      "HI :  मेरी जवाबों किया\n",
      "\n",
      "EN :  First Quarter\n",
      "HI :  प्रथम कार्यपट्टी\n",
      "\n",
      "EN :  Synchronization failed\n",
      "HI :  सिंक्रोनाइजेशन\n",
      "\n",
      "EN :  Image histogram adjust curves plugin for digiKam\n",
      "HI :  डिज़ीकैम के लिए डॉक्टर प्रदर्शत\n",
      "\n",
      "EN :  Tea Cooker\n",
      "HI :  चाय केतली\n",
      "\n",
      "EN :  Delay of audio relative to video\n",
      "HI :  विंडोज़ के आरपार क्रमांक के लिए एक अक्षों के टच तेज के एटीई नक्शा में टाइलें के लिए पूछें\n",
      "\n",
      "EN :  Do not save data\n",
      "HI :  डाटा फॉर्मेट्स\n",
      "\n",
      "EN :  Cannot start\n",
      "HI :  लेट प्रारंभ नहीं किया जा सके नहीं गया है\n",
      "\n",
      "EN :  No Description\n",
      "HI :  कोई वर्णन नहीं\n",
      "\n",
      "EN :  Do not use Color Correction\n",
      "HI :  रंग सुधार शैली नहीं करें\n",
      "\n",
      "EN :  Add New Static Host\n",
      "HI :  नया तेज अभिलेख जोड़ें\n",
      "\n",
      "EN :  Strip whitespace when executing an action\n",
      "HI :  जब कार्य को चालू हो\n",
      "\n",
      "EN :  Add Group\n",
      "HI :  नोट जोड़ें\n",
      "\n",
      "EN :  Yi Syllables\n",
      "HI :  उपकरणः\n",
      "\n",
      "EN :  That town is two miles away\n",
      "HI :  <UNK> बहुत नाज़ हैं उसे प्रविष्टियाँ\n",
      "\n",
      "EN :  Insert Cell\n",
      "HI :  कक्ष प्रविष्ट करें\n",
      "\n",
      "EN :  Move to Bottom Left\n",
      "HI :  खड़ा नीचे खिसकाएँ\n",
      "\n",
      "EN :  Explosion decay\n",
      "HI :  सीए फ़्लोटिंग हैं\n",
      "\n",
      "EN :  Hide Comment\n",
      "HI :  सीडीडीबी वातावरण छुपाएँ\n",
      "\n",
      "EN :  Auto Replace\n",
      "HI :  ऊपर का नाम\n",
      "\n",
      "EN :  Illegal method name\n",
      "HI :  अवैध जुड़ने नाम\n",
      "\n",
      "EN :  lower boundary of the plot range\n",
      "HI :  प्लाट सीमा का प्रबंधन स्थिति त्रुटि\n",
      "\n",
      "EN :  Allow Zero Size\n",
      "HI :  निर्देशांक पुछल्ले\n",
      "\n",
      "EN :  Additional Elements\n",
      "HI :  चित्र योग\n",
      "\n",
      "EN :  New Web Shortcut\n",
      "HI :  जमाएं या सेकण्ड\n",
      "\n",
      "EN :  He has no <UNK> of right and wrong\n",
      "HI :  उसकी सेवाओं की <UNK> तथा इसे पहले क्या <UNK> है कि भी और <UNK> साफ़ किया जाए तो फिर\n",
      "\n",
      "EN :  Download From Camera\n",
      "HI :  कैमरा से छवियाँ\n",
      "\n",
      "EN :  Current color\n",
      "HI :  मौजूदा रंग\n",
      "\n",
      "EN :  He left his parents when he was eight years old\n",
      "HI :  उसने मुझसे रहने के प्रथमाक्षर था\n",
      "\n",
      "EN :  Use pattern\n",
      "HI :  निजी उपयोग करने के लिए औजार संपादन करें\n",
      "\n",
      "EN :  Select Input Coordinates\n",
      "HI :  इनपुट परिवर्धित चुनें\n",
      "\n",
      "EN :  Construct a vector to this point\n",
      "HI :  इस बिन्दु इस सदिश के रूप में ईमेल सहेजें\n",
      "\n",
      "EN :  Show names of comets near the Sun\n",
      "HI :  चैनल की <UNK> का परिणाम दिखाएँ\n",
      "\n",
      "EN :  Kontact Summary\n",
      "HI :  टेक्स मूल्य\n",
      "\n",
      "EN :  General Properties\n",
      "HI :  सामान्य गुण\n",
      "\n",
      "EN :  Could Not Rename Temporary File\n",
      "HI :  आज फ़ाइल का नाम नहीं कर सका\n",
      "\n",
      "EN :  Last Image\n",
      "HI :  अंतिम आकार\n",
      "\n",
      "EN :  Gray Scale\n",
      "HI :  धूसर वर्णन\n",
      "\n",
      "EN :  Enables the Leitner system for the active vocabulary\n",
      "HI :  बाहरी विशिष्ट कमांड के लिए केडीई दिया गया हों अपलोड किया जाना है\n",
      "\n",
      "EN :  String\n",
      "HI :  अ\n",
      "\n",
      "EN :  mode\n",
      "HI :  मोड मात्रा\n",
      "\n",
      "EN :  Open Medium Folder\n",
      "HI :  सक्रिय फ़ोल्डर खोलें\n",
      "\n",
      "EN :  Now Playing\n",
      "HI :  सीवीएस का पालन\n",
      "\n",
      "EN :  unknown size\n",
      "HI :  नया आकार से लघु छवि आकार\n",
      "\n",
      "EN :  View Frame Information\n",
      "HI :  फ्रेम जानकारी\n",
      "\n",
      "EN :  Width of board\n",
      "HI :  वास्तविक वस्तुओं के लिए लाइन हस्ताक्षरित करें\n",
      "\n",
      "EN :  Create New Folder\n",
      "HI :  नया वर्ग जोड़ें\n",
      "\n",
      "EN :  Down\n",
      "HI :  उपयोग में बजाता\n",
      "\n",
      "EN :  Mail Options\n",
      "HI :  छवियाँ विकल्प\n",
      "\n",
      "EN :  Max size\n",
      "HI :  अधिकतम आकार\n",
      "\n",
      "EN :  Decreases subtitle delay\n",
      "HI :  सबटाइटल देरी बढ़ाएँ\n",
      "\n",
      "EN :  Duplicate widget\n",
      "HI :  बेनाम दिखाएँ\n",
      "\n",
      "EN :  Perspective grid\n",
      "HI :  पर्सपेक्टिव ग्रिड\n",
      "\n",
      "EN :  I don t think I can wait that long\n",
      "HI :  मुझे उसके लिए सुन नहीं कर दिया था कि टॉम मुझे नहीं चल रहा तुम्हारे खुश हैं उसे तो\n",
      "\n",
      "EN :  Send certificate\n",
      "HI :  प्रमाणपत्र मिटाना\n",
      "\n",
      "EN :  Add a table of content\n",
      "HI :  क्षेत्र के टच कुंजीपट ख़ाका सहेजें\n",
      "\n",
      "EN :  is not\n",
      "HI :  यह नहीं\n",
      "\n",
      "EN :  Open Files\n",
      "HI :  मॉड्यूल खोलें\n",
      "\n",
      "EN :  Yi Radicals\n",
      "HI :  जियोग्राफिक\n",
      "\n",
      "EN :  Flip\n",
      "HI :  खड़ा पलटें\n",
      "\n",
      "EN :  You are not <UNK> to play baseball here\n",
      "HI :  आप बैकगेमॉन आइडियोग्राफ्स खोलना है उसने पूछा उनके लिए कृपया आपको ठीक क्षेत्र तुम डॉक्टर ने उस मीटिंग रिसोर्स\n",
      "\n",
      "EN :  Insert an object from another program\n",
      "HI :  अन्य टैब से एक खण्ड बनाएँ\n",
      "\n",
      "EN :  Frame Shape\n",
      "HI :  फ्रेम आकार बदलें\n",
      "\n",
      "EN :  Resize document window to fit document size\n",
      "HI :  दस्तावेज़ का विषय को नया नाम प्रदर्शित करने के लिए आपके पास में भंडारित करें\n",
      "\n",
      "EN :  Crop Settings\n",
      "HI :  घर विन्यास\n",
      "\n",
      "EN :  Clear Diagram\n",
      "HI :  आरेख साफ करें\n",
      "\n",
      "EN :  Sorting Behavior\n",
      "HI :  एक्जइफ का रंग\n",
      "\n",
      "EN :  Flip image complete\n",
      "HI :  छवि चौड़ाई\n",
      "\n",
      "EN :  My Map Searches\n",
      "HI :  मुझे पिछला समय\n",
      "\n",
      "EN :  Export theme to file\n",
      "HI :  फ़ाइल में निर्यात करें\n",
      "\n",
      "EN :  TIFF Files\n",
      "HI :  फ़ाइलें फ़ाइल\n",
      "\n",
      "EN :  Shortcut\n",
      "HI :  फोटोग्राफ\n",
      "\n",
      "EN :  I was disappointed that you didn t call\n",
      "HI :  मैं <UNK> उससे कुछ फ़र्क नहीं करूँगा\n",
      "\n",
      "EN :  Configure Hidden Objects\n",
      "HI :  टिप्पणियाँ कॉन्फ़िगर करें\n",
      "\n",
      "EN :  You had plenty of time\n",
      "HI :  समय के <UNK> जाएंगे\n",
      "\n",
      "EN :  Check for the computer to play\n",
      "HI :  पैटर्न के गुणों में मास्क को दाईं उपयोक्ता मार्गदर्शक\n",
      "\n",
      "EN :  Allow application tips\n",
      "HI :  वेब डोमेन आवश्यक हो गया प्रयास\n",
      "\n",
      "EN :  He did it as he had been told\n",
      "HI :  उसने यह नदी के बिना छाता नहीं होती जाएगा है\n",
      "\n",
      "EN :  Work telephone number\n",
      "HI :  कार्य संख्या\n",
      "\n",
      "EN :  Add to Favorite Folders\n",
      "HI :  पसंदीदा फ़ोल्डर में संवाद किस्म\n",
      "\n",
      "EN :  Status Filter\n",
      "HI :  स्थिति अनुक्रम\n",
      "\n",
      "EN :  Stopped\n",
      "HI :  स्पॉट्स\n",
      "\n",
      "EN :  Filters which <UNK> the files that Strigi should ignore\n",
      "HI :  असफलता की आईडी समझा करें कि अधिक मूल चीज़ की वस्तुएँ लोड करें\n",
      "\n",
      "EN :  Change Point Style\n",
      "HI :  निर्देशिका पृष्ठ काटें\n",
      "\n",
      "EN :  Where are you going\n",
      "HI :  तुम कहाँ गए हैं क्या\n",
      "\n",
      "EN :  Cast a shadow on the horizon <UNK> by this line\n",
      "HI :  इस फ़ाइल <UNK> को रास्ते से चिट्ठियाँ बजाता है\n",
      "\n",
      "EN :  Reminder\n",
      "HI :  लंबी गया\n",
      "\n",
      "EN :  Whole\n",
      "HI :  इंटरफ़ेस\n",
      "\n",
      "EN :  Lines\n",
      "HI :  दोहराएँ\n",
      "\n",
      "EN :  Other Tabs\n",
      "HI :  अन्य विंडो\n",
      "\n",
      "EN :  Show camera flash settings\n",
      "HI :  कैमरा लूप पायथन ब्राउज़र दिखाएँ\n",
      "\n",
      "EN :  All\n",
      "HI :  सभी सक्षम करें\n",
      "\n",
      "EN :  I did it the way he told me to\n",
      "HI :  मुझे उससे मिलना नहीं लगता चलाने के पीछे प्रेषक मुझे मिला\n",
      "\n",
      "EN :  Clears all cached thumbnails\n",
      "HI :  <UNK> अपने बाल अन्य वस्तुओं को साफ करें\n",
      "\n",
      "EN :  Size In\n",
      "HI :  आकार लिया\n",
      "\n",
      "EN :  Scroll Line Down\n",
      "HI :  वर्तनी जांच संवाद\n",
      "\n",
      "EN :  A mother is responsible for the <UNK> of her children\n",
      "HI :  जापान से के बारे में बहुत सेवा का जवाब चाहिए\n",
      "\n",
      "EN :  Circle Reverse\n",
      "HI :  खाली प्रबंधन करें\n",
      "\n",
      "EN :  He reads the paper every morning\n",
      "HI :  चूहा काले कपड़े तैयार कर दिया\n",
      "\n",
      "EN :  Two Box Bottom In\n",
      "HI :  नीचे दाएं से बाहर\n",
      "\n",
      "EN :  Description\n",
      "HI :  क़िस्म\n",
      "\n",
      "EN :  Save Report\n",
      "HI :  वर्तमान में सहेजें\n",
      "\n",
      "EN :  Operation Settings\n",
      "HI :  ऑपरेशन विन्यास\n",
      "\n",
      "EN :  Opens the KPlayer key bindings dialog\n",
      "HI :  नए अलार्म आईडी बनाने में ओपन पीजीपी टैग जोड़ें जहाँ आप एक्सेसिबिलिटी विशेषताओं को एचटीएमएल दस्तावेज़ बनाने के पीछे\n",
      "\n",
      "EN :  Install new widgets\n",
      "HI :  नया छवि को प्रथम छवि\n",
      "\n",
      "EN :  Local printer\n",
      "HI :  स्थानीय इंसीडेंस\n",
      "\n",
      "EN :  Audio bitrate of this file\n",
      "HI :  इस फ़ाइल इस समूह का होस्टनाम\n",
      "\n",
      "EN :  Melting Point\n",
      "HI :  प्रूफ\n",
      "\n",
      "EN :  Clear row source\n",
      "HI :  पंक्ति पृष्ठ पाद सूचना पाठ शॉर्टकट चुनें\n",
      "\n",
      "EN :  Mixed Mode Type\n",
      "HI :  शैलियाँ पट्टी वित्तीय करें\n",
      "\n",
      "EN :  Active Uploads\n",
      "HI :  सक्रिय करें\n",
      "\n",
      "EN :  Compare these files or folders\n",
      "HI :  क्षेत्रों को इस फ़ाइलें तथा फ़ाइल सिस्टम में चयनित वाक्यांशों को दिखाएँ\n",
      "\n",
      "EN :  Expiry Age\n",
      "HI :  चौड़ा शब्दकोश पसंद\n",
      "\n",
      "EN :  Horizontal Wave\n",
      "HI :  आड़ा लहर\n",
      "\n",
      "EN :  Single player\n",
      "HI :  दोहरा स्क्रिप्ट\n",
      "\n",
      "EN :  This invitation has been canceled\n",
      "HI :  यह कुत्ता कौनसा खाया है\n",
      "\n",
      "EN :  Scope\n",
      "HI :  टीप\n",
      "\n",
      "EN :  Stop Slideshow\n",
      "HI :  टेलिफोन क्रमांक\n",
      "\n",
      "EN :  <UNK> and doing are two different things\n",
      "HI :  अभी तक उसपर अपनी अनुपात जो और परिवर्तन आपने यहाँ पर पहुँचना है कि पाने वाला रेगुलर बदलने का\n",
      "\n",
      "EN :  Message Group\n",
      "HI :  संदेश अगला\n",
      "\n",
      "EN :  Edit ChangeLog\n",
      "HI :  जमा करें\n",
      "\n",
      "EN :  Fixed Depth\n",
      "HI :  स्थिर सीमा\n",
      "\n",
      "EN :  engine details\n",
      "HI :  आलेख अनुकूलित करें\n",
      "\n",
      "EN :  Ask for name and folder when adding bookmarks\n",
      "HI :  उन्नत पढ़ा पता संदेश सभी संदेशों को जब फ़ाइलें रोटेशन के लिए विशिष्ट स्मरण तथा सक्रिय शीट को डाक\n",
      "\n",
      "EN :  Add to current activity\n",
      "HI :  प्रशिक्षण सेना में जोड़ें\n",
      "\n",
      "EN :  Inserts a new <UNK> into the file ChangeLog in the <UNK> folder\n",
      "HI :  फ़ाइल पी में फ़ाइलों को सहेजता है\n",
      "\n",
      "EN :  The query is correct\n",
      "HI :  शब्द सीमा तैयार किया जाए\n",
      "\n",
      "EN :  Circular\n",
      "HI :  खोज स्क्रिप्ट\n",
      "\n",
      "EN :  No info\n",
      "HI :  कोई फ़ोल्डर नहीं\n",
      "\n",
      "EN :  not installed\n",
      "HI :  हस्ताक्षर करें\n",
      "\n",
      "EN :  <UNK> the currently selected phrases in the history\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HI :  चयनित वाक्यांशों को वर्तमान में प्रदाता के इतिहास में चयनित वाक्यांशों को पढ़ें या बनाएँ\n",
      "\n",
      "EN :  Restart the computer\n",
      "HI :  तंत्र विन्यास\n",
      "\n",
      "EN :  Plugin Configuration\n",
      "HI :  प्लगइन कॉन्फ़िगरेशन\n",
      "\n",
      "EN :  Medium Outline\n",
      "HI :  मध्यम खराब बिट्स\n",
      "\n",
      "EN :  New Aggregation\n",
      "HI :  नए फॉर्मेट\n",
      "\n",
      "EN :  I had a <UNK> with my older brother yesterday\n",
      "HI :  मेरे पापा के <UNK> रुक दस्तावेज़ मुझे लगता कल कुंजियों पाया रुक पड़ी थी\n",
      "\n",
      "EN :  What s the story\n",
      "HI :  जब क्या यह यकीन है\n",
      "\n",
      "EN :  Show close buttons on tabs\n",
      "HI :  नौ में मुख्य भाग में स्क्रॉल पट्टी का संपादन करें\n",
      "\n",
      "EN :  September\n",
      "HI :  नई व्याख्यान\n",
      "\n",
      "EN :  Explosion force\n",
      "HI :  लंबी स्ट्रीमिंग\n",
      "\n",
      "EN :  Filters test\n",
      "HI :  असफल जाँच का हालिया बदलें\n",
      "\n",
      "EN :  Envelope Feed\n",
      "HI :  संख्या बदलें\n",
      "\n",
      "EN :  Ralf Mueller\n",
      "HI :  अफ़वाह सच छुपाता है\n",
      "\n",
      "EN :  By Size\n",
      "HI :  आकार\n",
      "\n",
      "EN :  Script Manager\n",
      "HI :  स्क्रिप्ट चलाएँ\n",
      "\n",
      "EN :  Click to stop window update\n",
      "HI :  हाल के विंडो के पीछे विंडो में सहेज दी\n",
      "\n",
      "EN :  File to load\n",
      "HI :  फ़ाइल को मिटाकर लिखें\n",
      "\n",
      "EN :  Reset after job\n",
      "HI :  कोई कमांड\n",
      "\n",
      "EN :  The king governed the country\n",
      "HI :  अपनी टीचर हैं\n",
      "\n",
      "EN :  Write PDF\n",
      "HI :  इंटरनेट से गणना\n",
      "\n",
      "EN :  Display the telescope position on the sky map\n",
      "HI :  अल्फ़ा <UNK> रोटेशन की प्रबंधन छोड़ें\n",
      "\n",
      "EN :  State of matter\n",
      "HI :  के अनुरूप\n",
      "\n",
      "EN :  Boiling point\n",
      "HI :  पृष्ठ पर\n",
      "\n",
      "EN :  Let s meet this afternoon\n",
      "HI :  तुम्हारे पास देखकर देखा\n",
      "\n",
      "EN :  Create Root Album Folder Failed\n",
      "HI :  यदि आप गलत फ़ोल्डरों या बदल ऑन करें\n",
      "\n",
      "EN :  Align Right\n",
      "HI :  बाएँ की गणना करें\n",
      "\n",
      "EN :  Save Current Search\n",
      "HI :  ट्रांसपोर्ट मिटाने के रूप में सहेजें\n",
      "\n",
      "EN :  Triangle\n",
      "HI :  एनोटेशन\n",
      "\n",
      "EN :  Add an item\n",
      "HI :  वर्ग जोड़ें\n",
      "\n",
      "EN :  Add Widgets\n",
      "HI :  कैप्चर जोड़ें जोड़ें\n",
      "\n",
      "EN :  Show events for today only\n",
      "HI :  तंत्र की सूचना में दिखाएँ\n",
      "\n",
      "EN :  What time is it\n",
      "HI :  समय <UNK> इंतेज़ार समय है\n",
      "\n",
      "EN :  Toggle display of constellation names\n",
      "HI :  नक्षत्र वेबसाइटों स्वचालित टॉगल करें\n",
      "\n",
      "EN :  Apply Metadata Template\n",
      "HI :  फ़ाइल रीप्लेस फ़ाइल सूची फ़ाइल घुमाया जा सका\n",
      "\n",
      "EN :  Would you just move along a bit please\n",
      "HI :  हम सब सेवाओं को फूलों को चुन सकते हैं खाली सीडी क्या <UNK> उपयोग करना चाहिए जिससे टाइल कामयाब\n",
      "\n",
      "EN :  Select Which Images to Import\n",
      "HI :  फ़ाइलें जोड़ने के लिए फ़ाइल जो संस्थापित करने के लिए कोई इमेज फ़ाइलों चुनें\n",
      "\n",
      "EN :  magnitude of faintest star <UNK> on map\n",
      "HI :  बच्चों लेखक पोंछना प्रभाव सक्षम होगी\n",
      "\n",
      "EN :  I will tell him about it when he comes next time\n",
      "HI :  रविवार <UNK> नियमों को पढ़ना बाहर जाने दिन थी\n",
      "\n",
      "EN :  No\n",
      "HI :  कोई नहीं\n",
      "\n",
      "EN :  Create Disconnected IMAP Account for KMail\n",
      "HI :  के मेल तस्वीर के लिए एक चिह्नित करें\n",
      "\n",
      "EN :  Torrent Limits\n",
      "HI :  ब्लॉक मोड\n",
      "\n",
      "EN :  Don t play with that <UNK>\n",
      "HI :  उक्त आता व्यापार किया जाएगा\n",
      "\n",
      "EN :  Search for images and videos missing date and time\n",
      "HI :  विजेट पहचान <UNK> और मेल बक्सा प्रदर्शन के बारे में से ढूंढें पंक्ति दिखाता है\n",
      "\n",
      "EN :  Buffer\n",
      "HI :  पूर्ण देखें\n",
      "\n",
      "EN :  Deep red\n",
      "HI :  गहरा मिले\n",
      "\n",
      "EN :  Root only\n",
      "HI :  सिर्फ माह\n",
      "\n",
      "EN :  Square\n",
      "HI :  वर्ग\n",
      "\n",
      "EN :  I had never seen her before that time\n",
      "HI :  मुझे नहीं वापस नहीं लगता कि टॉम और उसका और बर्दाश्त नहीं आया था कि वह नहीं पता नहीं\n",
      "\n",
      "EN :  Non Recursive\n",
      "HI :  आईमैप फैला\n",
      "\n",
      "EN :  letters\n",
      "HI :  मेक मिनट जिसपर वस्तुएँ\n",
      "\n",
      "EN :  Paint ladders\n",
      "HI :  तारे अक्षम\n",
      "\n",
      "EN :  Display atomic mass in the PSE\n",
      "HI :  वृत्तीय स्क्रीन औज़ार पर घुमाएँ\n",
      "\n",
      "EN :  Specifies the command to run\n",
      "HI :  डब्बा दृष्टिगोचर मिटाया गया\n",
      "\n",
      "EN :  Call of <UNK> member on destroyed object\n",
      "HI :  मैथ को इतिहास की ब्रिज में सहेजा गया पट्टी पर स्पॉट प्रारंभिक मेन्यू पट्टी पर पास <UNK> पंक्तियों के\n",
      "\n",
      "EN :  Edit Boot Images\n",
      "HI :  तय करता है\n",
      "\n",
      "EN :  Select Modem Type\n",
      "HI :  मॉडम फ़ाइलें चुनें\n",
      "\n",
      "EN :  the local directory to save the exported diagrams in\n",
      "HI :  अगले पृष्ठ में <UNK> में <UNK> को भिन्न में लॉगइन पर पाँच तीन अक्षों के <UNK> में इंटरनेट में\n",
      "\n",
      "EN :  Server started\n",
      "HI :  सर्वर प्रारंभ\n",
      "\n",
      "EN :  Feeds\n",
      "HI :  मैनुअल\n",
      "\n",
      "EN :  south\n",
      "HI :  लॉगिंग\n",
      "\n",
      "EN :  Remove recipient line\n",
      "HI :  थॉमस दस्तावेज़ मिटाएँ\n"
     ]
    }
   ],
   "source": [
    "myModel.eval()\n",
    "totalLoss = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs,_,lengths in test_loader:\n",
    "        print(\"\\nEN : \",\" \".join([ds.enDecoder[idx]\n",
    "            for idx in inputs.cpu()[0].numpy()[1:-1]]))\n",
    "        \n",
    "        outputs = myModel.predict(inputs,lengths)\n",
    "        print(\"HI : \",\" \".join([ds.hiDecoder[idx]\n",
    "            for idx in outputs[:-1] ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the results, it does look great...some of the sentences have been completely correctly classified! While some need a lot of imporvement and most of them are partly correct. The possible problems here could be fairly small architecture, small vocabulary. These are a few things to work on further..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastai] *",
   "language": "python",
   "name": "conda-env-fastai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
