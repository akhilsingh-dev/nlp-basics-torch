{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformers!\n",
    "\n",
    "Another architecture extensively used in NLP...A transformer can be viewed as a stack of encoders and decoders. I will be using the same dataset (English to Hindi Translation) but now I will be using a transformer to do so.\n",
    "\n",
    "More articles to read for a better view:\n",
    "\n",
    "http://jalammar.github.io/illustrated-transformer/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for file I/O\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "\n",
    "# for dataset and dataloader...\n",
    "from collections import Counter\n",
    "from torch.utils.data import Dataset,DataLoader,Subset\n",
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "# for model creation...\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# for model training...\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm,tqdm_notebook\n",
    "\n",
    "tqdm.pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='cuda')"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DATA_PATH = os.path.join(os.getcwd(),\"data\",\"english_to_hindi.txt\")\n",
    "DATA_PATH = \"D:\\\\PROJECTS\\\\Github\\\\nlp-basics\\\\data\\\\english_to_hindi.txt\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "EN    0\nHI    0\ndtype: int64\n"
    },
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EN</th>\n      <th>HI</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Help!</td>\n      <td>बचाओ!</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Jump.</td>\n      <td>उछलो.</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Jump.</td>\n      <td>कूदो.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Jump.</td>\n      <td>छलांग.</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Hello!</td>\n      <td>नमस्ते।</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "       EN       HI\n0   Help!    बचाओ!\n1   Jump.    उछलो.\n2   Jump.    कूदो.\n3   Jump.   छलांग.\n4  Hello!  नमस्ते।"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def readFile(path,chkNa=True):\n",
    "    \"\"\"\n",
    "        Load data from a text file. The file must have Lang1(delimiter)Lang2 in each row.\n",
    "        Eg : \"Hello Hallo\" or \"Hello Ola\" {here, delimiter was space} \n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(path,header=None,sep=\"\\t\",names=[\"EN\",\"HI\"])\n",
    "        if chkNa:\n",
    "            print(df.isna().sum())\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"{path} does not specify a text file.\")    \n",
    "    except OSError:\n",
    "        print(f\"{path} does not exist\")\n",
    "\n",
    "#checking to make sure...\n",
    "df = readFile(DATA_PATH)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "['मुझे', 'टिकटें', 'कहाँ', 'से', 'लेनीं', 'होंगीं']\n['Where', 'should', 'I', 'pick', 'the', 'tickets', 'up']\n['तुम', 'आज', 'सुबह', 'यहाँ', 'क्यों', 'आए']\n['Why', 'did', 'you', 'come', 'here', 'this', 'morning']\n"
    }
   ],
   "source": [
    "def clean(txt):\n",
    "    unwanted = \"~|\\\\/_।.?,*@#$%^&(){}[]=+\\\"-'\"\n",
    "    for char in unwanted:\n",
    "        txt = txt.replace(char,' ')\n",
    "    return txt\n",
    "\n",
    "def tokenize(txt):\n",
    "    txt = clean(txt) \n",
    "    tokens = txt.split()\n",
    "    return tokens\n",
    "\n",
    "for i in range(2008,2010):\n",
    "    #print(df[\"HI\"][i])\n",
    "    print(tokenize(df[\"HI\"][i]))\n",
    "    print(tokenize(df[\"EN\"][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EngHinData(Dataset):    \n",
    "    def __init__(self,path,maxVocabSize=500):\n",
    "        \"\"\"\n",
    "            Read a text file from path and generate the input and target sequences\n",
    "            Also generate english and hindi vocabulary with a max size.\n",
    "            The most commonly occuring words are chosen.\n",
    "        \"\"\"\n",
    "        self.maxVocabSize = maxVocabSize\n",
    "        \n",
    "        df = readFile(path,chkNa=False)\n",
    "        self.df = self.tokenizeDf(df)\n",
    "        \n",
    "        #Generate a vocabulary for both languages...\n",
    "        enVocab = self.mostFreqTokens(self.df.ENTokenized.tolist())\n",
    "        hiVocab = self.mostFreqTokens(self.df.HITokenized.tolist())\n",
    "        \n",
    "        #Replace rare tokens with \"<UNK>\"\n",
    "        self.replaceRareTokens(self.df)\n",
    "        #Impute zero length targets...\n",
    "        self.findZeroTargets()\n",
    "        #Remove all datarows with >20% unknowns...\n",
    "        self.df = self.removeHighUnk(self.df)\n",
    "        \n",
    "        # Create char maps and reverse char maps\n",
    "        self.enEncoder,self.enDecoder = self.generateMaps(enVocab,rev=True)\n",
    "        self.hiEncoder,self.hiDecoder = self.generateMaps(hiVocab,rev=True)\n",
    "        \n",
    "        # Add <BEG> and <END> to all tokens...\n",
    "        self.appendExtras(self.df)\n",
    "        \n",
    "        # change tokens to indices...\n",
    "        self.token2idx(self.df)\n",
    "        \n",
    "        # Drop all columns except num...\n",
    "        self.df.drop([\"level_0\",\"index\",\"EN\",\"HI\",\"ENTokenized\",\"HITokenized\"],axis=1,inplace=True)\n",
    "        self.df.reset_index(inplace=True)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def __getitem__(self,i):\n",
    "        return self.df.ENNum[i],self.df.HINum[i]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    \n",
    "    def token2idx(self,df):\n",
    "        df[\"ENNum\"] = df.ENTokenized.apply(lambda tokenList: [self.enEncoder[token] for token in tokenList])\n",
    "        df[\"HINum\"] = df.HITokenized.apply(lambda tokenList: [self.hiEncoder[token] for token in tokenList])\n",
    "    \n",
    "    \n",
    "    def appender(self,tokenList):\n",
    "        tokenList.insert(0,\"<BEG>\")\n",
    "        tokenList.append(\"<END>\")\n",
    "        return tokenList\n",
    "    \n",
    "        \n",
    "    def appendExtras(self,df):\n",
    "        \"\"\"\n",
    "            Adds <BEG> and <END> at the start and end of each tokenList\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        df.ENTokenized.apply(self.appender)\n",
    "        df.HITokenized.apply(self.appender)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def generateMaps(self,vocab,rev=False):\n",
    "        \"\"\"\n",
    "            Generates a dictionary {char : idx}\n",
    "            If rev is set to True, a reverse map will also be generated {idx : char}\n",
    "        \"\"\"\n",
    "        extras = [\"<PAD>\",\"<BEG>\",\"<END>\",\"<UNK>\"]    \n",
    "        charMap = {char : idx for idx,char in enumerate(vocab)}\n",
    "        for extra in extras:\n",
    "            charMap[extra] = len(charMap)\n",
    "        \n",
    "        if not rev:\n",
    "            return charMap\n",
    "        else:\n",
    "            revCharMap = {idx : char for char,idx in charMap.items()}\n",
    "            return charMap,revCharMap \n",
    "        \n",
    "    \n",
    "    def tokenizeDf(self,df):\n",
    "        df[\"ENTokenized\"] = df.EN.apply(tokenize)\n",
    "        df[\"HITokenized\"] = df.HI.apply(tokenize)\n",
    "        return df\n",
    "    \n",
    "    def replaceRareTokens(self,df):\n",
    "        commonInputs = self.mostFreqTokens(df.ENTokenized.tolist())\n",
    "        commonTargets = self.mostFreqTokens(df.HITokenized.tolist())\n",
    "        \n",
    "        df.loc[:, 'ENTokenized'] = df.ENTokenized.apply(\n",
    "            lambda tokens: [token if token in commonInputs \n",
    "                            else \"<UNK>\" for token in tokens]\n",
    "        )\n",
    "        df.loc[:, 'HITokenized'] = df.HITokenized.apply(\n",
    "            lambda tokens: [token if token in commonTargets\n",
    "                            else \"<UNK>\" for token in tokens]\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def mostFreqTokens(self,sequence):\n",
    "        allTokens = [word for sent in sequence for word in sent]\n",
    "        common_tokens = set(list(zip(*Counter(allTokens).most_common(self.maxVocabSize - 4)))[0])\n",
    "        return common_tokens\n",
    "    \n",
    "    def removeHighUnk(self, df, threshold=0.8):\n",
    "        \"\"\"Remove sequences with mostly <UNK>.\"\"\"\n",
    "        calculate_ratio = (\n",
    "            lambda tokens: sum(1 for token in tokens if token != '<UNK>')/ len(tokens) > threshold\n",
    "        )\n",
    "        \n",
    "        df = df[df.ENTokenized.apply(calculate_ratio)]\n",
    "        df = df[df.HITokenized.apply(calculate_ratio)]\n",
    "        df.reset_index(inplace=True)\n",
    "        return df\n",
    "    \n",
    "        \n",
    "    def findZeroTargets(self):\n",
    "        badVals = []\n",
    "        for i,val in enumerate(self.df.HITokenized.values):\n",
    "            if len(val)==0:\n",
    "                badVals.append(i)\n",
    "        \n",
    "        print(f\"Found {len(badVals)} bad values...Imputing them...\")\n",
    "        self.df.drop(badVals,axis=0,inplace=True)\n",
    "        self.df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Found 2 bad values...Imputing them...\n"
    }
   ],
   "source": [
    "ds = EngHinData(DATA_PATH,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.99 * len(ds))\n",
    "test_size = len(ds) - train_size\n",
    "train_ds, test_ds = torch.utils.data.random_split(ds, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence, pad_sequence\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "def collate(batch):\n",
    "    \n",
    "    inputs = [torch.LongTensor(item[0]) for item in batch]\n",
    "    targets = [torch.LongTensor(item[1]) for item in batch]\n",
    "    \n",
    "    \n",
    "    # Pad sequencse so that they are all the same length (within one minibatch)\n",
    "    padded_inputs = pad_sequence(inputs, padding_value=ds.enEncoder[\"<PAD>\"], batch_first=True)\n",
    "    padded_targets = pad_sequence(targets, padding_value=ds.hiEncoder[\"<PAD>\"], batch_first=True)\n",
    "    \n",
    "    \n",
    "    # Sort by length for CUDA optimizations\n",
    "    lengths = torch.LongTensor([len(x) for x in inputs])\n",
    "    lengths, permutation = lengths.sort(dim=0, descending=True)\n",
    "\n",
    "    return padded_inputs[permutation].to(device), padded_targets[permutation].to(device), lengths.to(device)\n",
    "\n",
    "\n",
    "batchSize = 512\n",
    "train_dl = DataLoader(train_ds, batch_size=batchSize, collate_fn=collate)\n",
    "test_dl = DataLoader(test_ds, batch_size=1, collate_fn=collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedder(nn.Module):\n",
    "    \n",
    "    def __init__(self,vocabSize,embDims):\n",
    "        super(Embedder,self).__init__()\n",
    "        self.embDims = embDims\n",
    "        self.emb = nn.Embedding(vocabSize,embDims)\n",
    "    \n",
    "    def forward(self,inputs):\n",
    "        return self.emb(inputs).cuda()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class PositionEmbedding(nn.Module):\n",
    "    \n",
    "    def __init__(self,seqLen,embDims,dropout=0.1):\n",
    "        super(PositionEmbedding,self).__init__()\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        pe = torch.zeros(seqLen, embDims)\n",
    "        \n",
    "        for pos in range(seqLen):\n",
    "            for i in range(0, embDims, 2):\n",
    "                pe[pos, i] = math.sin(pos / (10000 ** ((2 * i)/embDims)))\n",
    "                pe[pos, i + 1] = math.cos(pos / (10000 ** ((2 * (i + 1))/embDims)))\n",
    "        \n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        \n",
    "        # inputs(torch.Tensor): (batchSize x seqLen x embDims)\n",
    "    \n",
    "        seqLen = inputs.size(1)\n",
    "        pe = Variable(self.pe[:,:seqLen],requires_grad=False).cuda()\n",
    "        inputs = inputs + pe\n",
    "        return self.dropout(inputs).cuda()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMask(inputs,targets,opt):\n",
    "    inputMask = (inputs != opt[0]).unsqueeze(-2)\n",
    "\n",
    "    if targets is not None:\n",
    "        targetMask = (targets != opt[1]).unsqueeze(-2)\n",
    "        size = targets.size(1)\n",
    "        peekMask = getPeekMask(size,opt).cuda()\n",
    "        targetMask = targetMask & peekMask\n",
    "    \n",
    "    else:\n",
    "        targetMask = None\n",
    "\n",
    "    return inputMask,targetMask\n",
    "\n",
    "def getPeekMask(size,opt):\n",
    "\n",
    "    # Get upper triangle of ones...\n",
    "    peekMask = np.triu(np.ones((1,size,size)),k=1).astype('uint8')\n",
    "    # create the peek mask...\n",
    "    peekMask = Variable(torch.from_numpy(peekMask) == 0).cuda()\n",
    "    return peekMask\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Multi-head Attention layer\n",
    "\n",
    "Its a way of trying to find the word in a source language most important in current context for the target language.\n",
    "\n",
    "For eg:\n",
    "\n",
    "        **En**                **De**\n",
    "The cat ate the mouse.          Die Katze aß die Maus.\n",
    "\n",
    "Here, if the machine was predicting the 2nd word (Katze), the word to pay \"attention\" to in the source sentence would be \"Cat\".\n",
    "For more complicated sentences, one word can have multiple such words to pay attention to. This \"selection\" of words is done by the Attention layer. When we use multiple such \"selectors\" each trainable according to the data, we get a multi-head attention layer.\n",
    "\n",
    "A \"single head\" Attention layer uses three values to achieve this:\n",
    "1. K or keys\n",
    "2. V or values\n",
    "3. Q or queries\n",
    "\n",
    "\n",
    "Q is the embedded input recieved, K and V are learned parameters. We take inner product of K and Q, apply softmax and multiply the value to V to get the attention vector...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"\n",
    "        A multi-head attention layer as shown in the 2017 paper \"Attention is all you need\"\n",
    "    \"\"\"\n",
    "    def __init__(self,nHeads,embDims,dropout=0.2):\n",
    "        \"\"\"\n",
    "            The layer is basically a [batchSize x nHeads x seqLen x (embDims/nHeads)] tensor\n",
    "        \"\"\"\n",
    "        super(MultiHeadAttention,self).__init__()\n",
    "\n",
    "        self.embDims = embDims\n",
    "        self.splitDims = embDims//nHeads\n",
    "        self.nHeads = nHeads\n",
    "\n",
    "        self.queries = nn.Linear(embDims,embDims)\n",
    "        self.keys = nn.Linear(embDims,embDims)\n",
    "        self.values = nn.Linear(embDims,embDims)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.finalFC = nn.Linear(embDims,embDims)\n",
    "\n",
    "    \n",
    "    def forward(self,q,k,v,mask=None):\n",
    "        \"\"\" \n",
    "            Define the forward pass...\n",
    "        \"\"\"\n",
    "        batchSize = queries.size(0)\n",
    "\n",
    "        k = self.keys(k).view(batchSize,-1,self.nHeads,self.splitDims)\n",
    "        q = self.queries(q).view(batchSize,-1,self.nHeads,self.splitDims)\n",
    "        v = self.keys(v).view(batchSize,-1,self.nHeads,self.splitDims)\n",
    "\n",
    "        k = k.transpose(1,2)\n",
    "        q = q.transpose(1,2)\n",
    "        v = v.transpose(1,2)\n",
    "\n",
    "        score = self.attention(q,k,v,mask)\n",
    "        out = score.transpose(1,2).contiguous().view(batchSize,-1,self.embDims)\n",
    "        return self.finalFC(out)\n",
    "\n",
    "\n",
    "    def attention(q,k,v,mask):\n",
    "        score = torch.matmul(q,k.transpose(-2,-1)) / math.sqrt(self.splitDims)\n",
    "        # If the mask is present...\n",
    "        if mask is not None:\n",
    "            mask.unsqueeze(1)\n",
    "            score = score.masked_fill(mask==0, -1e9)\n",
    "        \n",
    "        score = F.softmax(score,dim=-1)\n",
    "        score = self.dropout(score)\n",
    "        return torch.matmul(score,v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedFwd(nn.Module):\n",
    "    def __init__(self,embDims,ffSize=1024,dropout=0.1):\n",
    "        super(FeedFwd,self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(embDims,ffSize)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(ffSize,embDims)\n",
    "\n",
    "    def forward(self,inputs):\n",
    "        tmp = F.relu(self.fc1(inputs))        \n",
    "        return self.fc2(self.dropout(tmp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalizer(nn.Module):\n",
    "\n",
    "    def __init__(self,size,epsilon=1e-6):\n",
    "        super(Normalizer,self).__init__()\n",
    "        self.size = size\n",
    "        self.a = nn.Parameter(torch.ones(size))\n",
    "        self.b = nn.Parameter(torch.zeros(size))\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self,inputs):\n",
    "        # find out the mean and std dev...\n",
    "        mu = x.mean(dim=-1,keepdim=True)\n",
    "        sigma = x.std(dim=-1,keepdim=True)\n",
    "\n",
    "        # Add two learnable parameters to the Z score...\n",
    "        return self.a * (x - mu)/(sigma+self.epsilon) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self,embDims,nHeads,dropout=0.1):\n",
    "        super(Encoder,self).__init__()\n",
    "\n",
    "\n",
    "        self.norm1 = Normalizer(embDims)\n",
    "        self.norm2 = Normalizer(embDims)\n",
    "\n",
    "        self.MHA = MultiHeadAttention(nHeads,embDims,dropout)\n",
    "        self.fc = FeedFwd(embDims)\n",
    "        \n",
    "        self.drop = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self,inputs,mask):\n",
    "        # First normalize the data...\n",
    "        inputNorm1 = self.norm1(inputs)\n",
    "        # Send this to attention layer...\n",
    "        attn = self.MHA(inputNorm,inputNorm,inputNorm,mask)\n",
    "        #Add a shortcut path...\n",
    "        inputs = inputs + attn\n",
    "        #Normalize the data again...\n",
    "        inputNorm2 = self.norm2(inputs)\n",
    "        # Repeat with feed fwd layer...\n",
    "        return (inputs + self.drop(self.fc(inputNorm2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self,nHeads,embDims,dropout=0.1):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.norm1 = Normalizer(embDims)\n",
    "        self.norm2 = Normalizer(embDims)\n",
    "        self.norm3 = Normalizer(embDims)\n",
    "\n",
    "\n",
    "        self.MHA1 = MultiHeadAttention(nHeads,embDims,dropout)\n",
    "        self.MHA2 = MultiHeadAttention(nHeads,embDims,dropout)\n",
    "        self.fc = FeedFwd(embDims)\n",
    "        \n",
    "        self.drop = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,inputs,encOutputs,srcMask,trgMask):\n",
    "        # Normalize the data...\n",
    "        inputNorm1 = self.norm1(inputs)\n",
    "        # pass it to first MHA...\n",
    "        inputs = inputs + self.MHA1(inputNorm1,inputNorm1,inputNorm1,trgMask)\n",
    "        inputNorm2 = self.norm2(inputs)\n",
    "\n",
    "        #pass it to MHA that takes encOutput...\n",
    "        inputs = inputs + self.MHA2(inputNorm2,encOutputs,encOutputs,srcMask)\n",
    "        inputNorm3 = self.norm3(inputs)\n",
    "\n",
    "        #pass it through the feew forward layer... \n",
    "        return (inputs + self.drop(self.fc(inputNorm3)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def cloneLayer(module,N):\n",
    "    \"\"\"\n",
    "        Creates N deep copies of a \"module\" layer \n",
    "    \"\"\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderStack(nn.Module):\n",
    "    def __init__(self,vocabSize,seqLen,embDims,nHeads,stackSize):\n",
    "        super(EncoderStack,self).__init__()\n",
    "        self.stackSize = stackSize\n",
    "\n",
    "        # The embedding layers...\n",
    "        self.emb = Embedder(vocabSize,embDims)\n",
    "        self.pe = PositionEmbedding(seqLen,embDims)\n",
    "\n",
    "        # The stack of encoders...\n",
    "        self.layers = cloneLayer(Encoder(embDims,nHeads),stackSize)\n",
    "\n",
    "        # A final normalizer...\n",
    "        self.norm = Normalizer(embDims)\n",
    "\n",
    "    \n",
    "    def forward(self,inputs,mask):\n",
    "        \n",
    "        inputs = self.emb(inputs)\n",
    "        inputs = self.pe(inputs)\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            inputs = layer(inputs,mask)\n",
    "\n",
    "        return self.norm(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderStack(nn.Module):\n",
    "    def __init__(self,seqLen,vocabSize,embDims,nHeads,stackSize):\n",
    "        super(DecoderStack,self).__init__()\n",
    "        self.stackSize = stackSize\n",
    "\n",
    "        self.emb = Embedder(vocabSize,embDims)\n",
    "        self.pe = PositionEmbedding(seqLen,embDims)\n",
    "\n",
    "        self.layers = cloneLayer(Decoder(embDims,nHeads),stackSize)\n",
    "\n",
    "        self.norm = Normalizer(embDims)\n",
    "    \n",
    "    def forward(self,inputs,encOutputs,srcMask,trgMask):\n",
    "\n",
    "        inputs = self.emb(inputs)\n",
    "        inputs = self.pe(inputs)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            inputs = layer(inputs,encOutputs,srcMask,trgMask)\n",
    "        \n",
    "        return self.norm(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The transformer....finally!\n",
    "\n",
    "After hours of solving problems, fixing tensor sizes and scouring through SO for the solutions, finally its here :')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self,srcVocab,trgVocab,seqLen,embDims,nHeads,stackSize):\n",
    "        super(Transformer,self).__init__()\n",
    "\n",
    "        self.encoder = EncoderStack(srcVocab,seqLen,embDims,nHeads,stackSize)\n",
    "        self.decoder = DecoderStack(trgVocab,seqLen,embDims,nHeads,stackSize)\n",
    "        self.out = nn.Linear(embDims,trgVocab)\n",
    "\n",
    "    \n",
    "    def forward(self,inputs,targets,srcMask,trgMask):\n",
    "        self.encOutputs = self.encoder(inputs,srcMask)\n",
    "        self.decOutputs = self.decoder(inputs,encOutputs,srcMask,trgMask)\n",
    "        outputs = self.out(decOutputs)\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "embDims = 300\n",
    "nHeads = 8\n",
    "stackSize = 6\n",
    "\n",
    "x,y,l = next(iter(train_dl))\n",
    "\n",
    "seqLen = x.size(1)\n",
    "srcVocab = ds.maxVocabSize\n",
    "trgVocab = ds.maxVocabSize\n",
    "\n",
    "myModel = Transformer(srcVocab,trgVocab,seqLen,embDims,nHeads,stackSize)\n",
    "for p in myModel.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.kaiming_normal_(p)\n",
    "\n",
    "optim = torch.optim.Adam(myModel.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a824de195fb445aa701096b13d273c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": "HBox(children=(IntProgress(value=0, max=50), HTML(value='')))"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of backend CPU but got backend CUDA for argument #3 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-00c729671357>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[0mtrainModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyModel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-22-00c729671357>\u001b[0m in \u001b[0;36mtrainModel\u001b[1;34m(model, train_dl, optimizer, epochs)\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0msrcMask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrgMask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreateMask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0myIn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0myIn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msrcMask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrgMask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrg_pad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\fastai\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-9a4ecfe8d85b>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs, targets, srcMask, trgMask)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtargets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msrcMask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrgMask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencOutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msrcMask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecOutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencOutputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msrcMask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrgMask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecOutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\fastai\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-00da9a85d414>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs, mask)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0memb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\fastai\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-c853ac0ae334>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0memb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\fastai\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\fastai\\lib\\site-packages\\torch\\nn\\modules\\sparse.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    112\u001b[0m         return F.embedding(\n\u001b[0;32m    113\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\envs\\fastai\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   1465\u001b[0m         \u001b[1;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1466\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1467\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1468\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected object of backend CPU but got backend CUDA for argument #3 'index'"
     ]
    }
   ],
   "source": [
    "def trainModel(model,train_dl,optimizer,epochs):\n",
    "    model.train()\n",
    "    start = time.time()\n",
    "    temp = start\n",
    "    totalLoss = []\n",
    "    progressBar = tqdm_notebook(train_dl)\n",
    "    opt = [ds.enEncoder[\"<PAD>\"],ds.hiEncoder[\"<PAD>\"]]\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epochLoss = 0\n",
    "        for x,y,l in progressBar:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            x.transpose(0,1)\n",
    "            y.transpose(0,1)\n",
    "            yIn = y[:,:-1]\n",
    "            y = y[:,1:].contiguous().view(-1)\n",
    "\n",
    "            srcMask,trgMask = createMask(x,yIn,opt)\n",
    "\n",
    "            preds = model(x,yIn,srcMask,trgMask)\n",
    "            loss = F.cross_entropy(preds.view(-1,preds.size(-1)),y,ignore_index=trg_pad)\n",
    "            loss.backward()\n",
    "            progressBar.set_description(f\"Loss : {loss.item():.3f}\")\n",
    "            optimizer.step()\n",
    "            epochLoss += loss.item()\n",
    "        \n",
    "        totalLoss.append(epochLoss)\n",
    "\n",
    "\n",
    "trainModel(myModel,train_dl,optim,5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:fastai] *",
   "language": "python",
   "name": "conda-env-fastai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}